{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import seaborn as sns\n",
    "\n",
    "from scipy import stats\n",
    "from datetime import datetime, timedelta\n",
    "from dateutil.parser import parse\n",
    "from sklearn.model_selection import train_test_split\n",
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "from IPython.display import display as dsp\n",
    "\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "register_matplotlib_converters()\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# United States Drug Prices: Forecasting and Analysis\n",
    "\n",
    "## Abstract\n",
    "\n",
    "We want to explore and describe the US drug market, both in terms of general trends and the price of individual drugs on the market. The purpose of this analysis is to explore what features impact how and why drug prices change, to create a reliable metric for market volatility, and to analyse and forecast trends in drug prices. As a part of this analysis, we have explored the relationship between generic and branded drugs and their prices, net market price, percent change and date. We then used Auto Regressive and Moving Averages modeling to perform more detailed time series analysis and forecasting of both our market volatility metric and the individual drug prices."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Collection\n",
    "\n",
    "The dataset we will be performing this analysis on is the [NADAC Comparison Dataset](https://data.medicaid.gov/Drug-Pricing-and-Payment/NADAC-Comparison). The NADAC Comparison Dataset is the log of every drug price change submitted to the National Drug Acquisition Cost database. We have a record of every FDA approved drug price change to work with.\n",
    "\n",
    "To access this data, we will be using an API to pull the dataset directly from the website. The API has some SoQL functionality implemented, we are capable of selecting the number of entires that we want to pull from the date of 11/28/2013"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Socrata SQL query\n",
    "SODA = '$limit=500000'\n",
    "URL = 'https://data.medicaid.gov/resource/444w-ftrz.csv?{}'.format(SODA)\n",
    "\n",
    "TRAIN_SPLIT = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_unique_counts(df):\n",
    "    column_name, unique_values_count, datatype = [], [], []\n",
    "    results = pd.DataFrame()\n",
    "    for col in df.columns:\n",
    "        #print(col, '\\t\\t\\t', len(df[str(col)].unique()))\n",
    "        column_name.append(col)\n",
    "        unique_values_count.append(len(df[str(col)].unique()))\n",
    "        datatype.append(df[str(col)].dtype)\n",
    "    \n",
    "    results['Column_Name'] = column_name\n",
    "    results['Unique_Value_Count'] = unique_values_count\n",
    "    results['Data_Type'] = datatype\n",
    "    \n",
    "    dsp(results)\n",
    "    print('Total Number of Changes: {}'.format(df.shape[0]))\n",
    "    \n",
    "    print('Total Number Observations: ', df.shape[0])\n",
    "\n",
    "def train_split(df, TRAIN_SPLIT):\n",
    "    split_point = int(len(df) * (TRAIN_SPLIT))\n",
    "    train = df[:split_point]\n",
    "    test = df[split_point:]\n",
    "    return train, test\n",
    "\n",
    "def strip_time(date):\n",
    "    date = date.replace('T00:00:00.000', '')\n",
    "    return datetime.strptime(date, '%Y-%m-%d')\n",
    "\n",
    "def return_name(ndc_description):\n",
    "    if len(ndc_description) == 0:\n",
    "        return '','','',''\n",
    "    drug_name, dosage, dosage_unit, drug_form = [], np.nan, np.nan, np.nan\n",
    "    \n",
    "    #Check and see if we are dealing with concentration\n",
    "    concentration = False\n",
    "    if set('%') <= set(ndc_description):\n",
    "        concentration = True\n",
    "        ndc_description.replace('%', '')\n",
    "    \n",
    "    #Create our array of words\n",
    "    words = ndc_description.split()\n",
    "    \n",
    "    for i in range(len(words)):\n",
    "        if not words[i].replace('.','').replace('%', '').isnumeric():\n",
    "            drug_name.append(words[i])\n",
    "            \n",
    "        if words[i].replace('.','').replace('%','').isnumeric():\n",
    "            dosage = float(words[i].replace('%', ''))\n",
    "            \n",
    "            if not concentration:\n",
    "                try:\n",
    "                    dosage_unit = words[i + 1]\n",
    "                    drug_form = ' '.join(words[i + 2:])\n",
    "                except:\n",
    "                    drug_form = ' '.join(words[i:])\n",
    "                    #print(ndc_description, concentration)\n",
    "                break\n",
    "            \n",
    "            if concentration:\n",
    "                dosage_unit = 'concentration'\n",
    "                drug_form = ' '.join(words[i + 1:])\n",
    "                break\n",
    "            \n",
    "    drug_name = ' '.join(drug_name)\n",
    "    return pd.Series([drug_name, dosage, dosage_unit, drug_form])\n",
    "\n",
    "def drop_na_printout(dataframe):\n",
    "    i = dataframe.shape[0]\n",
    "    j = dataframe.dropna().shape[0]\n",
    "    \n",
    "    percent_loss = (i - j) / i * 100\n",
    "    \n",
    "    print(percent_loss, '% data lost in cleaning.')\n",
    "    \n",
    "    return dataframe.dropna()\n",
    "\n",
    "def ts_lin_test(series):\n",
    "     return stats.linregress(range(len(series)), series.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Description\n",
    "\n",
    "The data herein contains price changes applied to the database. Each observation contains an 'ndc_description' string, which encapsulate the drug name, the dosage (including units of measurement) and the drug format. The 'ndc' column contains a serial particular to the label, product and package. The 'old_nadac_per_unit' and 'new_nadac_per_unit' describe the USD price listed per unit. \n",
    "\n",
    "The 'classification_for_rate_setting' tells us if the drug whose rate is being changed is labeled as generic or branded. The 'percent_change' gives us the percent change from the old to new price. The 'primary_reason' gives us the reason listed for the change and the 'start_date' tells us when the change is applied to the database.\n",
    "\n",
    "### Data Cleaning and Preparation\n",
    "\n",
    "Our most intensive issue at this point is the extraction of the drug name and dosage information from the ndc description. To perform a more comprehensive analysis, we will need to scale the price to the dosage of the drug. Not every ndc description follows the same format of drug name + dosage measure + units of measurement + format. A few drugs do not even include dosage measures and units of measurements, so we can expect some data loss at this point. We are able to extract information from drugs sold as a solution and in a solid form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = pd.read_csv(URL, parse_dates = True)\n",
    "\n",
    "#Convert dates to date format\n",
    "raw['start_date'] = raw['start_date'].apply(lambda x: strip_time(x))\n",
    "raw['end_date'] = raw['end_date'].apply(lambda x: strip_time(x))\n",
    "\n",
    "#Remove Effective Date\n",
    "raw = raw.drop('effective_date', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['ndc_description', 'ndc', 'old_nadac_per_unit', 'new_nadac_per_unit',\n",
      "       'classification_for_rate_setting', 'percent_change', 'primary_reason',\n",
      "       'start_date', 'end_date', 'days_effective', 'days_count',\n",
      "       'price_change', 'year-month', 'drug_name', 'dosage', 'dosage_unit',\n",
      "       'drug_form'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(raw.columns)\n",
    "\n",
    "#Create 'days_effective' and 'day_count' columns\n",
    "raw['days_effective'] = (raw['end_date'] - raw['start_date'])\n",
    "raw['days_effective'] = raw['days_effective'].apply(lambda x: x.days)\n",
    "\n",
    "raw['days_count'] = (raw['start_date'] - min(raw['start_date']))\n",
    "raw['days_count'] = raw['days_count'].apply(lambda x: x.days)\n",
    "\n",
    "#Create price change column\n",
    "raw['price_change'] = raw['new_nadac_per_unit'] - raw['old_nadac_per_unit']\n",
    "\n",
    "#Create 'month-year' column because most changes happen in the middle of every month\n",
    "raw['year-month'] = raw['start_date'].apply(lambda x: x.strftime('%Y-%m'))\n",
    "\n",
    "#Add drug name column, we want to ignore dosage and format\n",
    "raw[['drug_name', 'dosage','dosage_unit','drug_form']] = \\\n",
    "raw['ndc_description'].apply(lambda x: return_name(x))\n",
    "\n",
    "#Remove all first-date entries\n",
    "if len(raw['start_date'].unique()) > 1:\n",
    "    raw.drop(raw[raw['start_date'] == min(raw['start_date'])].index, inplace = True)\n",
    "\n",
    "#Remove last month of data, this is typically truncated by the limitations of our API call\n",
    "if len(raw['year-month']) > 3:\n",
    "    raw.drop(raw[raw['year-month'] == max(raw['year-month'])].index, inplace = True)\n",
    "\n",
    "    \n",
    "#Generate change_count df\n",
    "change_count = raw['ndc'].groupby('start_date').count()\n",
    "print('Our data represents the range of dates between {} and {}'.format(change_count.index.min().strftime('%Y-%m-%d'),\n",
    "                                                                        change_count.index.max().strftime('%Y-%m-%d')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove observations with missing entries.\n",
    "raw = drop_na_printout(raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scale price to dosage\n",
    "raw['daily_max_dosage'] = raw.groupby(['drug_name', 'start_date', 'dosage_unit'])['dosage'].transform('max')\n",
    "raw['scaled_old_per_unit'] = raw['daily_max_dosage'] / raw['dosage'] * raw['old_nadac_per_unit']\n",
    "raw['scaled_new_per_unit'] = raw['daily_max_dosage'] / raw['dosage'] * raw['new_nadac_per_unit']\n",
    "raw['scaled_percent_change'] = (raw['scaled_new_per_unit'] - raw['scaled_old_per_unit']) \\\n",
    "/ raw['scaled_old_per_unit'] * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ndc_description</th>\n",
       "      <th>ndc</th>\n",
       "      <th>old_nadac_per_unit</th>\n",
       "      <th>new_nadac_per_unit</th>\n",
       "      <th>classification_for_rate_setting</th>\n",
       "      <th>percent_change</th>\n",
       "      <th>primary_reason</th>\n",
       "      <th>end_date</th>\n",
       "      <th>days_effective</th>\n",
       "      <th>days_count</th>\n",
       "      <th>price_change</th>\n",
       "      <th>year-month</th>\n",
       "      <th>drug_name</th>\n",
       "      <th>dosage</th>\n",
       "      <th>dosage_unit</th>\n",
       "      <th>drug_form</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>start_date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-12-18</th>\n",
       "      <td>62</td>\n",
       "      <td>62</td>\n",
       "      <td>62</td>\n",
       "      <td>62</td>\n",
       "      <td>62</td>\n",
       "      <td>62</td>\n",
       "      <td>62</td>\n",
       "      <td>62</td>\n",
       "      <td>62</td>\n",
       "      <td>62</td>\n",
       "      <td>62</td>\n",
       "      <td>62</td>\n",
       "      <td>62</td>\n",
       "      <td>61</td>\n",
       "      <td>61</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-12-25</th>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-01-08</th>\n",
       "      <td>408</td>\n",
       "      <td>408</td>\n",
       "      <td>408</td>\n",
       "      <td>408</td>\n",
       "      <td>408</td>\n",
       "      <td>408</td>\n",
       "      <td>408</td>\n",
       "      <td>408</td>\n",
       "      <td>408</td>\n",
       "      <td>408</td>\n",
       "      <td>408</td>\n",
       "      <td>408</td>\n",
       "      <td>408</td>\n",
       "      <td>318</td>\n",
       "      <td>318</td>\n",
       "      <td>318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-01-15</th>\n",
       "      <td>18543</td>\n",
       "      <td>18543</td>\n",
       "      <td>18543</td>\n",
       "      <td>18543</td>\n",
       "      <td>18543</td>\n",
       "      <td>18543</td>\n",
       "      <td>18543</td>\n",
       "      <td>18543</td>\n",
       "      <td>18543</td>\n",
       "      <td>18543</td>\n",
       "      <td>18543</td>\n",
       "      <td>18543</td>\n",
       "      <td>18543</td>\n",
       "      <td>16024</td>\n",
       "      <td>16024</td>\n",
       "      <td>16024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-01-22</th>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            ndc_description    ndc  old_nadac_per_unit  new_nadac_per_unit  \\\n",
       "start_date                                                                   \n",
       "2013-12-18               62     62                  62                  62   \n",
       "2013-12-25               12     12                  12                  12   \n",
       "2014-01-08              408    408                 408                 408   \n",
       "2014-01-15            18543  18543               18543               18543   \n",
       "2014-01-22               19     19                  19                  19   \n",
       "\n",
       "            classification_for_rate_setting  percent_change  primary_reason  \\\n",
       "start_date                                                                    \n",
       "2013-12-18                               62              62              62   \n",
       "2013-12-25                               12              12              12   \n",
       "2014-01-08                              408             408             408   \n",
       "2014-01-15                            18543           18543           18543   \n",
       "2014-01-22                               19              19              19   \n",
       "\n",
       "            end_date  days_effective  days_count  price_change  year-month  \\\n",
       "start_date                                                                   \n",
       "2013-12-18        62              62          62            62          62   \n",
       "2013-12-25        12              12          12            12          12   \n",
       "2014-01-08       408             408         408           408         408   \n",
       "2014-01-15     18543           18543       18543         18543       18543   \n",
       "2014-01-22        19              19          19            19          19   \n",
       "\n",
       "            drug_name  dosage  dosage_unit  drug_form  \n",
       "start_date                                             \n",
       "2013-12-18         62      61           61         61  \n",
       "2013-12-25         12      11           11         11  \n",
       "2014-01-08        408     318          318        318  \n",
       "2014-01-15      18543   16024        16024      16024  \n",
       "2014-01-22         19      15           15         15  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "change_count.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create drugs dataframe\n",
    "drugs = raw[['drug_name','old_nadac_per_unit','new_nadac_per_unit']].groupby(['drug_name']).mean().rename(\n",
    "    {'old_nadac_per_unit' : 'old_average_per_unit','new_nadac_per_unit': 'new_average_per_unit'}, axis = 1)\n",
    "drugs['percent_average_change'] = (drugs['new_average_per_unit'] \n",
    "                                   - drugs['old_average_per_unit']) / drugs['new_average_per_unit'] * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_price, min_price, max_dosage = [], [], []\n",
    "for drug in drugs.index:\n",
    "    max_price.append(max(raw[raw['drug_name'] == drug]['new_nadac_per_unit']))\n",
    "    min_price.append(min(raw[raw['drug_name'] == drug]['new_nadac_per_unit']))\n",
    "    max_dosage.append(max(raw[raw['drug_name'] == drug]['dosage']))\n",
    "drugs['max_per_unit'] = max_price\n",
    "drugs['min_per_unit'] = min_price\n",
    "drugs['max_dosage'] = max_dosage\n",
    "drugs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('Max Price per Unit Distribution')\n",
    "plt.hist(drugs['max_per_unit'])\n",
    "\n",
    "plt.xlabel('Price per Unit')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metadata\n",
    "\n",
    "The first order of business with our data is to discern what datatype and how many unique entries are present in our raw dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\nUnique Values in Raw Data per Column:')\n",
    "list_unique_counts(raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of interest are two observations:\n",
    "\n",
    "First, the days effective, which describes how many days are between the 'start date' and the 'end date'. There are only two unique values listed in this column, 6 and 7. As the database updates on a weekly basis, this makes sense. We will be using the start date for our time series analysis.\n",
    "\n",
    "Second, there are an overwhelming numnber of ndc values as there are drug names, or even ndc descriptions. The ndc code represents specific batches and labels, which is information we are unable to take into account. It is far more useful to group by drug name or ndc description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Top value counts for NDC:')\n",
    "dsp(raw['ndc'].value_counts().sort_values(ascending = False).head())\n",
    "\n",
    "print('\\nTop value counts for NDC description:')\n",
    "dsp(raw['ndc_description'].value_counts().sort_values(ascending = False).head())\n",
    "\n",
    "print('\\nTop value counts for drug name:')\n",
    "dsp(raw['drug_name'].value_counts().sort_values(ascending = False).head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see the number of entries per ndc code and ndc description. The specificity of the ndc code means for the intent of our analysis, this can be ignored. The ndc description list also has an issue. Depeding on the number of unique dosages, drug names will be repeated multiple times. Since we are interested in individual drugs, we must consolidate this information into the drug name."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Distribution2350\n",
    "\n",
    "We create two dataframes, the first which contain columns from the raw dataset we are interested in for further analysis. The second with all numeric data remove. As we may also be interested in exploring outliers later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = raw[['drug_name','start_date', 'days_count', 'year-month', 'old_nadac_per_unit', 'new_nadac_per_unit', \\\n",
    "            'price_change','scaled_old_per_unit', 'scaled_new_per_unit', 'percent_change', 'scaled_percent_change']]\n",
    "\n",
    "#numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "data_out_rm = data[(np.abs(stats.zscore(data[['percent_change']])) < 3).all(axis = 1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Percent Change\n",
    "\n",
    "Percent change is a good metric for understanding how volatile individual drugs are, as it is a ratio measurement of change. However, it is not a good indicater to use when comparing drugs to other drugs as there is no indication of magnitude of price. For example, if a drug were to increase from 0.01$ to 0.02$, we would see a notable 50% increase, within the drug history, but the price itself would not be noteworthy when comparing a drug that changed from 100$ to 200$ per unit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('Percent Change Distribution')\n",
    "plt.hist(data['percent_change'])\n",
    "plt.xlabel('% change')\n",
    "plt.ylabel('N Obs')\n",
    "plt.show()\n",
    "\n",
    "plt.title('Percent Change Distribution, Outliers Removed')\n",
    "plt.hist(data_out_rm['percent_change'])\n",
    "plt.xlabel('% change')\n",
    "plt.ylabel('N Obs')\n",
    "plt.show()\n",
    "\n",
    "plt.title('Percent Change per Date')\n",
    "plt.scatter(data['start_date'], data['percent_change'])\n",
    "plt.xticks(rotation = 70)\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Percent Change')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw.groupby(['drug_name']).max().sort_values('percent_change', ascending = False)['percent_change'][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Price per Unit: de facto and scaled\n",
    "\n",
    "On the surface, even with outliers removed, it is clear that the distribution of prices per unit over the entire log is a steep exponential distribution. This shows that there are lots of drug changes where the final price of the drug change is fairly small. Our suspicions are confirmed when we group our data by average price per drug name. We are using the scaled price when observing this distribution as having multiple denominations of drugs may introduce scaling issues that prevent our data from fully reflecting the reality of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('New Price Per Unit')\n",
    "plt.hist(data_out_rm['new_nadac_per_unit'], color = 'green')\n",
    "plt.xlabel('Price per Unit')\n",
    "plt.ylabel('N Obs')\n",
    "plt.show()\n",
    "\n",
    "plt.title('New Price Per Unit (0, 1)')\n",
    "plt.hist(data['new_nadac_per_unit'], range = (0, 1), color = 'green')\n",
    "plt.xlabel('Price per Unit')\n",
    "plt.ylabel('N Obs')\n",
    "plt.show()\n",
    "\n",
    "drugmean = data.groupby(['drug_name']).mean()[['new_nadac_per_unit', 'scaled_new_per_unit']]\n",
    "plt.title('Average Price per Drug Name Distribution')\n",
    "plt.hist(drugmean['scaled_new_per_unit'], color = 'purple')\n",
    "plt.xlabel('Price')\n",
    "plt.ylabel('N Drugs')\n",
    "plt.show()\n",
    "\n",
    "plt.title('New Price to Date')\n",
    "plt.scatter(data['start_date'], data['new_nadac_per_unit'], color = 'green')\n",
    "plt.xticks(rotation = 70)\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Price per Unit')\n",
    "plt.show()\n",
    "\n",
    "#Price Differential\n",
    "#Remove Outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There appears to be some form of seasonality in the scatterplot for the price per unit data which does not appear to be reflected in the percent change scatterplot. This implies that the outliers here are indicitive of a single drug whose value is changed on a monthly or near monthly basis.\n",
    "\n",
    "When we compare the new nadac per unit to the scaled new nadac per unit, we can see that we have slightly altered the distribution. Our distribution has become marginally less sharp. This is a direct result of how we performed the scaling, where we scaled the drug price to the highest dosage, multiplying lower dosages by a scaling factor to raise the price to reflect the amount of active ingredient included."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('Scaled New Price Per Unit (0, 1)')\n",
    "plt.hist(data['new_nadac_per_unit'], range = (0, 1), color = 'green', alpha = 0.5)\n",
    "plt.hist(data['scaled_new_per_unit'], range = (0, 1), color = 'red', alpha = 0.5)\n",
    "red_patch = mpatches.Patch(color='red', label='Scaled Price per Unit')\n",
    "green_patch = mpatches.Patch(color='green', label='Price per Unit')\n",
    "plt.legend(handles = [red_patch, green_patch])\n",
    "plt.xlabel('Price per Unit')\n",
    "plt.ylabel('N Obs')\n",
    "plt.show()\n",
    "\n",
    "plt.title('Scaled New Price to Date')\n",
    "plt.scatter(data['start_date'], data['scaled_new_per_unit'], color = 'red')\n",
    "plt.xticks(rotation = 70)\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Price per Unit')\n",
    "plt.show()\n",
    "\n",
    "#Overlap Scaled and raw\n",
    "#Don't hard code the range"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Price Change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('Price Change Distribution')\n",
    "plt.hist(data_out_rm['price_change'])\n",
    "plt.xlabel('price change')\n",
    "plt.ylabel('N Obs')\n",
    "plt.show()\n",
    "\n",
    "plt.title('Price Change Distribution (-3, 3)')\n",
    "plt.hist(data_out_rm['price_change'], range = (-3, 3))\n",
    "plt.xlabel('price change')\n",
    "plt.ylabel('N Obs')\n",
    "plt.show()\n",
    "\n",
    "plt.title('Price Change per Date')\n",
    "plt.scatter(data['start_date'], data['price_change'])\n",
    "plt.xticks(rotation = 70)\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('price change')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The price change reflects the price differential between old and new price. This metric is more useful for comparing magnitude of changes between drugs rather than performance within drugs themselves. We may further improve the comparison by introducing a percentage factor. A high percentage with a high price differential implies prominence to the change as this implies a cheap drug becoming more expensive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\nTop drug name max price changes:')\n",
    "dsp(raw.groupby(['drug_name']).max().sort_values('price_change', ascending = False)['price_change'].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Correlation Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(data[['days_count', 'scaled_new_per_unit', 'percent_change', 'price_change']].corr())\n",
    "plt.title('Raw Data Correlation Heatmap')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we have our correlation matrix between some of our features of interest. Some points of interest here:\n",
    "\n",
    "1. We can infer that the number of days since the start and the percent change are strongly uncorrelated between individual observations. This implies that the percent change does not notably change with time.\n",
    "\n",
    "2. We can see that the price change and the scaled new price per unit are fairly well correlated, whereas the percent change is not. From this we can infer that the price of the drug is not a factor in the percent change of the drug.\n",
    "\n",
    "Naturally, this correlation map is a good indicator of correlating features within individual observations, but terrible at describing general trends within the data. There is the issue of sampling, the observations submitted on a day with fewer observations will be more heavily weighted than on a day with many observations when it comes to correlations with time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(data.groupby('year-month').mean()\\\n",
    "            [['days_count','scaled_new_per_unit', 'percent_change', 'price_change']].corr())\n",
    "\n",
    "plt.title('Daily Averages Correlation Heatmap')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Price = A * e ^ f(percent)\n",
    "\n",
    "df / dt < 0\n",
    "dPrice / dt > 0\n",
    "\n",
    "Here, we have grouped our data by month, and we can already see a greater spectrum of correlation. Again, we can note that the percent change is negatively correlated with the day count, but the price change is. This, combined with the correlation between day count and price per unit, is indicative of slowing exponential growth in the drug prices as every month drug prices increase by some diminishing percentage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generic VS Branded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('{}% of changes are to generic medicines.'.format(round(len(raw[raw['classification_for_rate_setting'] == 'G'])\n",
    "                                                              / raw.shape[0], 3) * 100))\n",
    "raw_generic = raw[raw['classification_for_rate_setting'] == 'G']['percent_change']\n",
    "raw_branded = raw[raw['classification_for_rate_setting'] == 'B']['percent_change']\n",
    "\n",
    "#Compare how often and the magnitude of change between generic and branded medicine.\n",
    "plt.title('Generic and Branded Percent Change Distribution')\n",
    "plt.hist(raw_generic, normed = True)\n",
    "plt.hist(raw_branded, normed = True)\n",
    "\n",
    "plt.xlabel('Percent Change')\n",
    "plt.ylabel('Proportions')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.title('Generic and Branded Percent Change Distribution (Outliers Excluded)')\n",
    "plt.hist(raw_generic[(np.abs(stats.zscore(raw_generic)) < 3)], normed = True)\n",
    "plt.hist(raw_branded[(np.abs(stats.zscore(raw_branded)) < 3)], normed = True)\n",
    "\n",
    "plt.xlabel('Percent Change')\n",
    "plt.ylabel('Proportions')\n",
    "plt.show()\n",
    "\n",
    "#Print Stats\n",
    "print('Mean Percent Change for Generic Drugs: {} percentage points'.format(round(raw_generic.mean() ,2)))\n",
    "print('Mean Percent Change for Branded Drugs: {} percentage points'.format(round(raw_branded.mean() ,2)))\n",
    "\n",
    "print('Standad Deviation for Generic Drugs: {} percentage points'.format(round(raw_generic.std() ,2)))\n",
    "print('Standad Deviation for Branded Drugs: {} percentage points'.format(round(raw_branded.std() ,2)))\n",
    "\n",
    "#T-test\n",
    "t_stat, p_val = stats.ttest_ind(raw_generic, raw_branded)\n",
    "\n",
    "print('T-Statistic: {}'.format(round(t_stat)))\n",
    "print('P-Value: {}'.format(round(p_val)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics for General Volatility\n",
    "\n",
    "What do we mean by volatility?\n",
    "\n",
    "Volatility is a measure of a system's proclivity to change. We want to create a metric that best describes the volatility of drug prices in the US. The changelog format of our dataset lends it well to exploring various measures of volatility.\n",
    "\n",
    "#### Changes per Day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('Changes Implemented Per Day')\n",
    "plt.plot(change_count.index.strftime('%Y-%m-%d'), change_count.values, '.')\n",
    "plt.xticks(np.arange(0,len(change_count.index), round((len(change_count.index)) / 8)), rotation = 70)\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('N Changes')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two glaring issues to note with using the total number of changes per day as a metric for market volatility. First, our database updates once a week, so the highest resolution we can get from the data is by week. Second, the vast majority of changes are submitted every four weeks. There may be something of interest in comparing the metrics of changes submitted on low volume days vs high volume days, but this is beyond the scope of this analysis. For now, we will look at the data at a montly resolution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Changes per Month\n",
    "\n",
    "On the surface, changelog entry counts make sense as a metric for market volatility. The more changes that are submitted, the more the market changes. This encapsulates new drugs entering the market and major drug pricing policy changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnth_count = raw['year-month'].value_counts().sort_index()\n",
    "plt.title('Changes per Month')\n",
    "plt.plot(mnth_count, '.')\n",
    "plt.xticks(np.arange(0,len(mnth_count.index), round((len(mnth_count.index)) / 8)), rotation = 70)\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('N Changes')\n",
    "plt.show()\n",
    "\n",
    "#Linearity test\n",
    "#slope, intercept, r_value, p_value, std_err = \n",
    "stats.linregress(range(len(mnth_count)), mnth_count.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can clearly see a linear trend within the data here, with a fairly high r-value. This data would be good to use in a model as a result of its linearity. Conceptually, using gross number of changes per period also makes sense, as a period with a higher number of changes could be considered more 'volatile'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Average Percent Change per Month\n",
    "\n",
    "We can also measure volatility by looking at the average percent change per month. This gives us an indication as to how much each drug is changing in comparison to itself. This is a good metric for taking into account the magnitude rate of change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnth_avgs = raw.groupby(['year-month']).mean()\n",
    "plt.title('Average Monthly Percent Change')\n",
    "plt.plot(mnth_avgs['percent_change'], '.')\n",
    "plt.xticks(np.arange(0,len(mnth_avgs.index), round((len(mnth_avgs.index)) / 8)), rotation = 70)\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Average Price Change')\n",
    "plt.show()\n",
    "\n",
    "stats.linregress(range(len(mnth_avgs['percent_change'])), mnth_avgs['percent_change'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our linear regression test shows the negative correlation we had observed before, but the linearity is fairly poor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('Average Monthly Percent Change Distribution')\n",
    "mnth_avgs['percent_change'].hist()\n",
    "plt.xlabel('Percent Change')\n",
    "plt.ylabel('Observations')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Total Price Gain/Loss per Month\n",
    "\n",
    "Another potential metric for market volatility we may use is the total price gain/loss per month. Essentially, we take the sum of every entry in the changelog per month as our metric. This is a direct measure of price, but is more sensitive to individual drugs with many different dosages being changed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw['total_price_change'] = raw['new_nadac_per_unit'] - raw['old_nadac_per_unit']\n",
    "mnth_sum = raw.groupby(['year-month']).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('Total Price Change per Month')\n",
    "plt.plot(mnth_sum['total_price_change'], '*')\n",
    "plt.xticks(np.arange(0,len(mnth_sum.index), round((len(mnth_sum.index)) / 8)), rotation = 70)\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Total Price Change')\n",
    "plt.show()\n",
    "stats.linregress(range(len(mnth_sum['total_price_change'])), mnth_sum['total_price_change'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see positive trends in the data, however, the linearity is still fairly low.\n",
    "\n",
    "Unfortunately, limited by our dataset, we do not have a complete picture of the supply and demand for drugs in the US. For that, we would need to introduce data which included information regarding how many units of every drug are purchased. However, we can infer some information regarding the volatility with any of the data above. To that end I will be using the total count log as my metric of volatility."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preliminary ARIMA modeling\n",
    "\n",
    "Auto Regression and Moving Averages is an ideal model to use with this data. ARIMA modeling is exceptional at working with time series data as it is exceptional at picking up longer term linear trends (AR) and short term/seasonal events (MA). Lets look at how well ARIMA modeling works with our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate the correlation within these and their respective p-values\n",
    "count_arima = ARIMA(mnth_count, order=(0,1,1)) #Play around with the order (110 101)\n",
    "p_chng_arima = ARIMA(mnth_avgs['percent_change'], order=(1,1,1))\n",
    "tot_chng = ARIMA(mnth_sum['total_price_change'], order=(1,1,1))\n",
    "\n",
    "count_arima_fit = count_arima.fit()\n",
    "p_chng_arima_fit = p_chng_arima.fit()\n",
    "tot_chng_fit = tot_chng.fit()\n",
    "\n",
    "print(count_arima_fit.summary())\n",
    "print('\\n\\n\\n')\n",
    "print(p_chng_arima_fit.summary())\n",
    "print('\\n\\n\\n')\n",
    "print(tot_chng_fit.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "count_arima_fit.plot_predict(start = mnth_count.index[1],end = max(mnth_count.index))\n",
    "plt.title('Entry Count per Month ARIMA Model')\n",
    "plt.ylabel('Entries')\n",
    "\n",
    "p_chng_arima_fit.plot_predict(start = mnth_avgs.index[1],end = max(mnth_avgs.index))\n",
    "plt.title('Average Percent Change per Month ARIMA Model')\n",
    "plt.ylabel('Percent Change')\n",
    "\n",
    "tot_chng_fit.plot_predict(start = mnth_sum.index[1],end = max(mnth_sum.index))\n",
    "plt.title('Total Price Change per Month ARIMA Model')\n",
    "plt.ylabel('Total Price Change per Day')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, our chosen metric for \n",
    "\n",
    "### Model Performance\n",
    "\n",
    "We can evaluate model performance by observing the plot and histogram of the residuals, that is the difference at every point between observed and predicted values for our measure at every available point in time. Ideally, the residuals scatter plot would show no correlation between day and magnitude, and that the histogram for the residuals would show a normal distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals_count = pd.DataFrame(count_arima_fit.resid)\n",
    "residuals_count.plot(legend=False)\n",
    "plt.title('Time Series of Count Residuals')\n",
    "residuals_count.hist(bins=20)\n",
    "plt.title('Histogram of Count Residuals')\n",
    "\n",
    "residuals_p_chng = pd.DataFrame(p_chng_arima_fit.resid)\n",
    "residuals_p_chng.plot(legend=False)\n",
    "plt.title('Time Series of Mean Percent Change Residuals')\n",
    "residuals_p_chng.hist(bins=20)\n",
    "plt.title('Histogram of Mean Percent Change Residuals')\n",
    "\n",
    "residuals_tot_chng = pd.DataFrame(tot_chng_fit.resid)\n",
    "residuals_tot_chng.plot(legend=False)\n",
    "plt.title('Time Series of Total Change Residuals')\n",
    "residuals_tot_chng.hist(bins=20)\n",
    "plt.title('Histogram of Total Change Residuals')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, in terms of monthly data, we do not have very many datapoints to fill out our histogram. We can still use these models to make decent predictions with the resolution we have.\n",
    "\n",
    "It appears that the ARIMA model when applied to the total monthly entry counts performs best. The distribution is begining to look normal and the residuals do not appear to have much of a correlation. We may increase the number of datapoints at a later time; however, the best approach to doing so would be to use some form of distributed computing methodology given the sheer size of the entire database."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drug Name: Record Count and Price Change\n",
    "\n",
    "Before we move on to forecasting, lets look at the correlation between features specific to trends within individual drugs. We want to know how the record counts, the average percent change and the price correlate with one another between individual drugs. This may offer us some clues as to what features would best be used to predict the prices of our drugs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a dataframe for every drug name\n",
    "drugs = pd.DataFrame(index = raw['drug_name'].unique())\n",
    "\n",
    "drugs['value_counts'] = raw.groupby(['drug_name']).count()['ndc']\n",
    "drugs['average_price_per_unit'] = raw.groupby(['drug_name']).mean()['new_nadac_per_unit']\n",
    "drugs['average_scaled_price_per_unit'] = raw.groupby(['drug_name']).mean()['scaled_new_per_unit']\n",
    "drugs['average_percent_change'] = raw.groupby(['drug_name']).mean()['percent_change']\n",
    "\n",
    "drugs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('Pearson Correlation')\n",
    "sns.heatmap(drugs[['value_counts','average_scaled_price_per_unit', 'average_percent_change']].corr())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, there is not much intercorrelation between any of our features of interest. The average percent change is very slightly correlated with the price per unit when we group by drugs, implying that more expensive drugs tend to receive higher percent increases. The average percent change appears to be nearly perfectly uncorrelated with the value counts, this implies that the value counts have nothing to do with what percent changes are applied to the drug prices."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forecasting\n",
    "\n",
    "#### Individual Drugs\n",
    "\n",
    "__By NDC Description__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find most frequently changed ndc prices\n",
    "top_n_drug_name = raw['drug_name'].value_counts().sort_values(ascending = False)[:25]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forecasting\n",
    "\n",
    "#### Market Volatility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we will forecast the next two years of monthly entry counts\n",
    "#We have already trained the model on the training set, and now we can validate it on the test set.\n",
    "\n",
    "#count_arima_fit.predict()\n",
    "size = int(len(mnth_count) * TRAIN_SPLIT)\n",
    "test =  mnth_count[size:len(mnth_count)]\n",
    "\n",
    "mnth_count.sort_index()\n",
    "#Create prediction array\n",
    "\n",
    "\n",
    "#Create array of timestamps:\n",
    "\n",
    "#plt.plot(mnth_count, color = 'blue')\n",
    "\n",
    "count_arima_fit.plot_predict(start = mnth_count.index[1],end = max(mnth_count.index))\n",
    "plt.title('Entry Counts per Date Forecast')\n",
    "#plt.xticks(np.arange(0,len(mnth_count.index), round((len(mnth_count.index)) / 8)), rotation = 70)\n",
    "plt.legend(loc = 'upper left')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('N Changes')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_date = mnth_count.index[2]\n",
    "print(my_date, type(my_date))\n",
    "\n",
    "print(min(mnth_count.index))\n",
    "print(mnth_count.index)\n",
    "print(mnth_count.shape)\n",
    "print(type(min(mnth_count.index)))\n",
    "#print(type(datetime.timestamp(min(mnth_count.index))))\n",
    "\n",
    "print(min(mnth_count.index), type(min(mnth_count.index)))\n",
    "\n",
    "#count_arima_fit.plot_predict(start = mnth_count.index[1],end = mnth_count.index[-1])\n",
    "\n",
    "print(mnth_count.index[-1])\n",
    "print(type(mnth_count.index[-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Individual Drug Names\n",
    "\n",
    "Rather than attempting to create and explore a model for every one of the 2350 unique drug names available in the dataset, we will instead be looking at the the top 25 most often changed drugs. The sampling methodology we use here is biased; however, we may be able to do some inferrence between this and the trends in drug prices we have seen before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create dictionary to store models.\n",
    "arima_models = {}\n",
    "coefficient = []\n",
    "p_value = []\n",
    "\n",
    "#LISINOPRIL\n",
    "\n",
    "for i, drug in enumerate(top_n_drug_name.index):\n",
    "    drug_history = raw[raw['drug_name'] == str(drug)].groupby(['year-month']).mean()\n",
    "    try:\n",
    "        arima_models[drug] = ARIMA(drug_history['scaled_new_per_unit'], order = (1,1,1)).fit()\n",
    "    #Fall through for non-stationarity\n",
    "    except:\n",
    "        arima_models[drug] = ARIMA(drug_history['scaled_new_per_unit'], order = (0,1,1)).fit()\n",
    "    \n",
    "    #Plot results\n",
    "    arima_models[drug].plot_predict(start = drug_history.index[1],end = max(drug_history.index))\n",
    "    plt.title('{} history'.format(drug))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An interesting trend we can see amongst the top 25 highest change count drugs is that most of these have a general downward trend. I would hypothesize that this is a result of such drugs being sold under generic labels, being sold with more dosages and more manufacturers having manufacturing rights for these drugs, thus increasing the number of ndc labels that refer to these particular drug names.\n",
    "\n",
    "For example, ibuprofen is a common pain relief and anti-inflamitory over the counter drug widely available in almost every grocery store. There are many different generic label brands that manufacture ibuprofen. Exploring the relationship between availability, usage, and demand for drugs would be an interesting and fruitful extension to this analysis, provided such data could be found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create nice visual aid\n",
    "#for i, drug in enumerate(top_n_drug_name.index):\n",
    "#    plt.subplot(5, 5, i + 1)\n",
    "#    arima_models[drug].plot_predict(start = drug_history.index[1],end = max(drug_history.index))\n",
    "    \n",
    "#plt.show()\n",
    "\n",
    "print(raw[raw['start_date'] == raw['start_date'][0]]['percent_change'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check the average percent change between drug at beginning and end of time frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "We were able to pull out many interesting insights within the drug pricing market.\n",
    "\n",
    "At its most general level, we can see that drug prices are undergoing exponential growth. \n",
    "We were able to explore a metric for market volatility and create a servicable model for forecasting purposes. As well as create a dictionary of models for the top 25 most common drug name entries.\n",
    "\n",
    "__NOTE__: Expand conclusion, summary.\n",
    "\n",
    "\n",
    "## Further Work\n",
    "\n",
    "I would have liked to encorporate a measure of the effects of major medical administration policy changes using A/B testing. With the current discourse surrounding the US healthcare system, it would be interesting to see what policy changes have had what effects on drug prices. We could get a more comprehensive picture of healthcare changes by encorporating other datasets from other sections of the industry, such as hospital billing and procedures. As well as encorporating data from other countries for comparison.\n",
    "\n",
    "As mentioned before, when looking at a purly economic standpoint, we could get a more comprehensive picture of drug performances by looking at some metrics for drug supply and demand. What we have been using only has given us a single facet of the marketplace.\n",
    "\n",
    "Finally, if we could find a comprehensive database which lists all the use cases and the effects of the drugs we have gone over, we could perform some insightful clustering that could tell us how similar and different drugs perform on the marketplace."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
